{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key = os.getenv(\"OPENAI_TEST_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chroma', 'data', 'test_openAI_API.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='ANTONIO OCHOTORENA  LAYNEZ  \\n+34 636 426 538  • antonioochotorena@gmail.com  • LinkedIn  • GitHub  \\n \\nSummary   \\n \\nActively seeking a full -time opportunity in data and AI in Amsterdam.  My background in consulting \\nand data science has equipped me with the skills to excel in a position where effective \\ncommunication and technical expertise are essential . What sets me apart is my strong drive to learn, \\nproactive approach to solving complex problems, and commitment to fostering a collaborative team \\nenvironment where we support and help each other to achieve shared goals.  \\n \\nExperience   \\n \\nInfosys  Instep – Global Internship Program  Bangalore, India  \\nAI Software Engineer  06/2024 – Now  \\n \\n• Developed a proprietary information retrieval module utilizing Large Language Models \\n(LLMs) and OCR technologies to extract healthcare forms, achieving substantial cost savings.  \\n• Implemented a RAG model for HR platforms during the Infosys BizHacks Hackathon, with \\nthe solution planned for future integration.  \\n  \\nMinsait Business Consulting  Madrid, Spain  \\nData Engineer  09/2021  – 08/2023  \\n  \\n• Led the successful D WH Platform migration for Beam Suntory Spain, encompassing SSIS \\ndevelopment and maintenance (SSIS, SAP and Salesforce).   \\n• Designed and implemented reporting tools to empower Beam Suntory Spain Finance, \\nOperations, and BI departments coordinating a group of  consultants.  \\n• Implemented a comprehensive documentation process resulting in a 58% faster resolution of \\nissues, enhancing efficiency and problem -solving capabilities.  \\n \\nRamón Y Cajal Hospital (IRYCIS)   Madrid, Spain  \\nData Engineer  01/2021  – 09/2021  \\n  \\n• Created a Support Decision System utilizing Deep Learning to predict cardiac diseases from 12 -\\nLead ECGs obtaining a competitive performance at the Physionet/CinC Challenge 2020 .  \\n• Developed and maintained a scalable webservice for processing thermal images from hospital \\ndatabases saving up to 30% of physicians time.  \\n• Designed Natural Language Processing (NLP) pipelines for biomedical document classification \\n(link to publication ). \\n \\nSpanish National Cancer Research Center  Madrid, Spain  \\nBiomedical Engineer  02/2019  – 05/2019  \\n  \\n Education   \\n \\nMSc Data Science University of Amsterdam  09/2023 – 06/2024  \\n \\nMSc Biomedical Engineering,  Polytechnic University of Madrid  09/2019 – 05/2021  \\n \\nBSc Biomedical Engineering,  Polytechnic University of Madrid  09/2014 – 06/2019   \\nOther competences   \\n \\n• Spanish (Native), English (C1 – Cambridge CAE), French (B1 – Alliance Française ). \\n• Python,  R, SQL, Pandas, Scikit -learn, Tensorflow, SSIS, AWS, Azure, PowerBI, Spark, Hadoop, \\nFlask, Docker , Causal Inference Modelling  and A/B testing , Informatica IDQ . \\n• Certified Professional SCRUM master, Stanford Machine Learning, Deeplearning.ai Deep \\nLearning Specialization , Hands on Hadoop, Microsoft SQL 70 -461.  ')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the pdf with the CV information\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"./data/CV_AntonioOchotorena_092024.pdf\")\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text \n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='ANTONIO OCHOTORENA  LAYNEZ  \\n+34 636 426 538  • antonioochotorena@gmail.com  • LinkedIn  • GitHub  \\n \\nSummary   \\n \\nActively seeking a full -time opportunity in data and AI in Amsterdam.  My background in consulting \\nand data science has equipped me with the skills to excel in a position where effective \\ncommunication and technical expertise are essential . What sets me apart is my strong drive to learn,'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='communication and technical expertise are essential . What sets me apart is my strong drive to learn, \\nproactive approach to solving complex problems, and commitment to fostering a collaborative team \\nenvironment where we support and help each other to achieve shared goals.  \\n \\nExperience   \\n \\nInfosys  Instep – Global Internship Program  Bangalore, India  \\nAI Software Engineer  06/2024 – Now  \\n \\n• Developed a proprietary information retrieval module utilizing Large Language Models'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='AI Software Engineer  06/2024 – Now  \\n \\n• Developed a proprietary information retrieval module utilizing Large Language Models \\n(LLMs) and OCR technologies to extract healthcare forms, achieving substantial cost savings.  \\n• Implemented a RAG model for HR platforms during the Infosys BizHacks Hackathon, with \\nthe solution planned for future integration.  \\n  \\nMinsait Business Consulting  Madrid, Spain  \\nData Engineer  09/2021  – 08/2023'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='the solution planned for future integration.  \\n  \\nMinsait Business Consulting  Madrid, Spain  \\nData Engineer  09/2021  – 08/2023  \\n  \\n• Led the successful D WH Platform migration for Beam Suntory Spain, encompassing SSIS \\ndevelopment and maintenance (SSIS, SAP and Salesforce).   \\n• Designed and implemented reporting tools to empower Beam Suntory Spain Finance, \\nOperations, and BI departments coordinating a group of  consultants.'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='Operations, and BI departments coordinating a group of  consultants.  \\n• Implemented a comprehensive documentation process resulting in a 58% faster resolution of \\nissues, enhancing efficiency and problem -solving capabilities.  \\n \\nRamón Y Cajal Hospital (IRYCIS)   Madrid, Spain  \\nData Engineer  01/2021  – 09/2021  \\n  \\n• Created a Support Decision System utilizing Deep Learning to predict cardiac diseases from 12 -'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='Data Engineer  01/2021  – 09/2021  \\n  \\n• Created a Support Decision System utilizing Deep Learning to predict cardiac diseases from 12 -\\nLead ECGs obtaining a competitive performance at the Physionet/CinC Challenge 2020 .  \\n• Developed and maintained a scalable webservice for processing thermal images from hospital \\ndatabases saving up to 30% of physicians time.  \\n• Designed Natural Language Processing (NLP) pipelines for biomedical document classification \\n(link to publication ).'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='• Designed Natural Language Processing (NLP) pipelines for biomedical document classification \\n(link to publication ). \\n \\nSpanish National Cancer Research Center  Madrid, Spain  \\nBiomedical Engineer  02/2019  – 05/2019  \\n  \\n Education   \\n \\nMSc Data Science University of Amsterdam  09/2023 – 06/2024  \\n \\nMSc Biomedical Engineering,  Polytechnic University of Madrid  09/2019 – 05/2021  \\n \\nBSc Biomedical Engineering,  Polytechnic University of Madrid  09/2014 – 06/2019   \\nOther competences'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='BSc Biomedical Engineering,  Polytechnic University of Madrid  09/2014 – 06/2019   \\nOther competences   \\n \\n• Spanish (Native), English (C1 – Cambridge CAE), French (B1 – Alliance Française ). \\n• Python,  R, SQL, Pandas, Scikit -learn, Tensorflow, SSIS, AWS, Azure, PowerBI, Spark, Hadoop, \\nFlask, Docker , Causal Inference Modelling  and A/B testing , Informatica IDQ . \\n• Certified Professional SCRUM master, Stanford Machine Learning, Deeplearning.ai Deep'),\n",
       " Document(metadata={'source': './data/CV_AntonioOchotorena_092024.pdf', 'page': 0}, page_content='• Certified Professional SCRUM master, Stanford Machine Learning, Deeplearning.ai Deep \\nLearning Specialization , Hands on Hadoop, Microsoft SQL 70 -461.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# store it to Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antonio\\AppData\\Local\\Temp\\ipykernel_12728\\1400787014.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embedding = OpenAIEmbeddings(api_key = os.getenv(\"OPENAI_TEST_KEY\"))\n"
     ]
    }
   ],
   "source": [
    "# Store it into a ChromaDB database\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(api_key = os.getenv(\"OPENAI_TEST_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "PERSIST_DIR = './chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=PERSIST_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO create a Summariser of job requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_requirements = \"\"\"\n",
    "<req1> AI experience </req1>\n",
    "<req2> MLOps </req2>\n",
    "<req3> Backend developer </req3>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"\"\"\n",
    "Use the following pieces of context to create a cover letter for the following job offer. \n",
    "{offer_requirements}\n",
    "If the applicant has knowledge gaps from the job offer: \n",
    "    1. Compare it to similar skills he has.\n",
    "    2. If there are no similar exclude them from the cover letter and metion them at the end.\n",
    "\n",
    "Don't try to make up an answer. \n",
    "Use a letter format with three paragraphs maximum. \n",
    "Keep the answer clear, concise and semi-formal as possible.\n",
    "Do not over extend with adjectives.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question\n",
    "{context}\n",
    "Question: {question}\n",
    "Cover letter: Fill in the letter here\n",
    "Knowledge Gaps: Add Knowledge Gaps if Any\n",
    "\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature=0, api_key = os.getenv(\"OPENAI_TEST_KEY\"))\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antonio\\AppData\\Local\\Temp\\ipykernel_12728\\4094420968.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my interest in the AI, MLOps, and Backend Developer position at your company. With my experience as an AI Software Engineer at Infosys, where I developed proprietary information retrieval modules using Large Language Models, I believe I have the technical expertise required for this role. My proactive approach to problem-solving and commitment to fostering a collaborative team environment align well with the values of your organization.\n",
      "\n",
      "In my role at Infosys, I successfully implemented a RAG model for HR platforms during a hackathon, showcasing my ability to work on complex projects and deliver innovative solutions. Additionally, my certification as a Professional SCRUM master and completion of Stanford Machine Learning and Deeplearning.ai Deep Learning Specialization courses demonstrate my dedication to continuous learning and growth in the field of AI.\n",
      "\n",
      "While I do not have direct experience in MLOps, I am confident in my ability to quickly learn and adapt to new technologies and processes. My background in data engineering at Minsait Business Consulting in Madrid has equipped me with the necessary skills to excel in a backend developer role, where I can leverage my experience with data processing and analysis.\n",
      "\n",
      "Thank you for considering my application. I am excited about the opportunity to contribute to your team and further develop my skills in AI, MLOps, and backend development.\n",
      "\n",
      "Sincerely,\n",
      "Antonio Ochotorena Laynez\n",
      "\n",
      "Knowledge Gaps: MLOps\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"\\nUse the following pieces of context to create a cover letter for the following job offer. \\n\\n<req1> AI experience </req1>\\n<req2> MLOps </req2>\\n<req3> Backend developer </req3>\\n\\nIf the applicant has knowledge gaps from the job offer: \\n    1. Compare it to similar skills he has.\\n    2. If there are no similar exclude them from the cover letter and metion them at the end.\\n\\nDon't try to make up an answer. \\nUse a letter format with three paragraphs maximum. \\nKeep the answer clear, concise and semi-formal as possible.\\nDo not over extend with adjectives.\\n\",\n",
       " 'result': 'Dear Hiring Manager,\\n\\nI am writing to express my interest in the AI, MLOps, and Backend Developer position at your company. With my experience as an AI Software Engineer at Infosys, where I developed proprietary information retrieval modules using Large Language Models, I believe I have the technical expertise required for this role. My proactive approach to problem-solving and commitment to fostering a collaborative team environment align well with the values of your organization.\\n\\nIn my role at Infosys, I successfully implemented a RAG model for HR platforms during a hackathon, showcasing my ability to work on complex projects and deliver innovative solutions. Additionally, my certification as a Professional SCRUM master and completion of Stanford Machine Learning and Deeplearning.ai Deep Learning Specialization courses demonstrate my dedication to continuous learning and growth in the field of AI.\\n\\nWhile I do not have direct experience in MLOps, I am confident in my ability to quickly learn and adapt to new technologies and processes. My background in data engineering at Minsait Business Consulting in Madrid has equipped me with the necessary skills to excel in a backend developer role, where I can leverage my experience with data processing and analysis.\\n\\nThank you for considering my application. I am excited about the opportunity to contribute to your team and further develop my skills in AI, MLOps, and backend development.\\n\\nSincerely,\\nAntonio Ochotorena Laynez\\n\\nKnowledge Gaps: MLOps',\n",
       " 'source_documents': [Document(metadata={'page': 0, 'source': './data/CV_AntonioOchotorena_092024.pdf'}, page_content='communication and technical expertise are essential . What sets me apart is my strong drive to learn, \\nproactive approach to solving complex problems, and commitment to fostering a collaborative team \\nenvironment where we support and help each other to achieve shared goals.  \\n \\nExperience   \\n \\nInfosys  Instep – Global Internship Program  Bangalore, India  \\nAI Software Engineer  06/2024 – Now  \\n \\n• Developed a proprietary information retrieval module utilizing Large Language Models'),\n",
       "  Document(metadata={'page': 0, 'source': './data/CV_AntonioOchotorena_092024.pdf'}, page_content='AI Software Engineer  06/2024 – Now  \\n \\n• Developed a proprietary information retrieval module utilizing Large Language Models \\n(LLMs) and OCR technologies to extract healthcare forms, achieving substantial cost savings.  \\n• Implemented a RAG model for HR platforms during the Infosys BizHacks Hackathon, with \\nthe solution planned for future integration.  \\n  \\nMinsait Business Consulting  Madrid, Spain  \\nData Engineer  09/2021  – 08/2023'),\n",
       "  Document(metadata={'page': 0, 'source': './data/CV_AntonioOchotorena_092024.pdf'}, page_content='ANTONIO OCHOTORENA  LAYNEZ  \\n+34 636 426 538  • antonioochotorena@gmail.com  • LinkedIn  • GitHub  \\n \\nSummary   \\n \\nActively seeking a full -time opportunity in data and AI in Amsterdam.  My background in consulting \\nand data science has equipped me with the skills to excel in a position where effective \\ncommunication and technical expertise are essential . What sets me apart is my strong drive to learn,'),\n",
       "  Document(metadata={'page': 0, 'source': './data/CV_AntonioOchotorena_092024.pdf'}, page_content='• Certified Professional SCRUM master, Stanford Machine Learning, Deeplearning.ai Deep \\nLearning Specialization , Hands on Hadoop, Microsoft SQL 70 -461.')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_completion(prompt, client):\n",
    "    \n",
    "#     completion = client.chat.completions.create(\n",
    "#                     model=\"gpt-3.5-turbo-0125\",\n",
    "#                     messages=[\n",
    "#                         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#                         {\"role\": \"user\", \"content\": prompt}\n",
    "#                     ],\n",
    "#                     max_tokens=1000,\n",
    "#                     temperature=0,\n",
    "#                 )\n",
    "#     return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pages[0].page_content\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Please follow the following format:\n",
    "<role 1> <reasons based on experience> <areas of improvement towards role 1>\n",
    "<role 2> <reasons based on experience> <areas of improvement towards role 2>\n",
    "<role 3> <reasons based on experience> <areas of improvement towards role 3>\n",
    "\n",
    "Do not do more than 3 roles\n",
    "```{text}```\n",
    "\"\"\"\n",
    "result = get_completion(prompt, client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Engineer at Infosys Instep in Amsterdam\n",
      "Antonio has a strong background in data engineering, as evidenced by his successful DWH platform migration for Beam Suntory Spain and the development of a Support Decision System using Deep Learning at Ramón Y Cajal Hospital. He has experience in leading projects, implementing reporting tools, and designing NLP pipelines for biomedical document classification. Antonio's technical skills in Python, R, SQL, and various data tools make him well-suited for a Data Engineer role.\n",
      "\n",
      "Areas of improvement:\n",
      "- Antonio could focus on enhancing his knowledge of cloud platforms like AWS and Azure to stay updated with the latest technologies in data engineering.\n",
      "- Developing expertise in big data technologies like Spark and Hadoop would further strengthen his profile for data engineering roles.\n",
      "\n",
      "AI Software Engineer in Amsterdam\n",
      "Antonio's experience in developing an information retrieval module using Large Language Models and OCR technologies at Infosys Instep showcases his expertise in AI. His proactive approach to problem-solving and commitment to learning align well with the requirements of an AI Software Engineer role. Antonio's participation in hackathons and competitive challenges demonstrates his ability to innovate and deliver solutions in AI projects.\n",
      "\n",
      "Areas of improvement:\n",
      "- Antonio could benefit from further deepening his knowledge in advanced AI concepts like reinforcement learning and generative models to broaden his skill set as an AI Software Engineer.\n",
      "- Engaging in more collaborative AI projects or open-source contributions could help Antonio gain practical experience in deploying AI solutions at scale.\n",
      "\n",
      "Biomedical Engineer at Spanish National Cancer Research Center\n",
      "Antonio's background in biomedical engineering, particularly in developing a Support Decision System for predicting cardiac diseases and designing NLP pipelines for biomedical document classification, highlights his expertise in this field. His ability to leverage deep learning and data analysis techniques for healthcare applications positions him well for roles in biomedical engineering.\n",
      "\n",
      "Areas of improvement:\n",
      "- Antonio could explore opportunities to work on interdisciplinary projects that combine data science and biomedical engineering to further enhance his skills in both domains.\n",
      "- Pursuing additional certifications or courses in healthcare analytics or medical imaging analysis could help Antonio stay abreast of the latest advancements in biomedical engineering.\n"
     ]
    }
   ],
   "source": [
    "print(result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
